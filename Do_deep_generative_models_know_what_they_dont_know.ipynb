{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cyanos/Workspace/OOD_Generative_models/score_flow-main/venv/lib/python3.10/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cyanos/Workspace/OOD_Generative_models/score_flow-main/venv/lib/python3.10/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "os.environ['XLA_FLAGS']='--xla_gpu_strict_conv_algorithm_picker=false'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import datasets\n",
    "import likelihood\n",
    "import sde_lib\n",
    "import losses\n",
    "from models import utils as mutils\n",
    "import logging\n",
    "import flax\n",
    "from typing import Any\n",
    "from flax.training import checkpoints\n",
    "# Keep the import below for registering all model definitions\n",
    "from models import ncsnpp\n",
    "import matplotlib.pyplot as plt\n",
    "from bpd_eval import convert_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.subvp.svhn_ddpmpp_continuous import get_config\n",
    "config = get_config()\n",
    "config.eval.batch_size = 16\n",
    "workdir = 'outs/cifar10_subvp_likelihood_tw'\n",
    "eval_folder=\"test_eval_interpolate_cifar_cifar\"\n",
    "eval_dir = os.path.join(workdir, eval_folder)\n",
    "checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "tf.io.gfile.makedirs(eval_dir)\n",
    "rng = jax.random.PRNGKey(config.seed + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data.dataset = 'CIFAR10'\n",
    "_, cifar_eval, _ = datasets.get_non_batch_dataset(config,\n",
    "                                        additional_dim=None,\n",
    "                                        uniform_dequantization=True, evaluation=True)\n",
    "config.data.dataset = 'SVHN'\n",
    "_, svhn_eval, _ = datasets.get_non_batch_dataset(config,\n",
    "                                        additional_dim=None,\n",
    "                                        uniform_dequantization=True, evaluation=True)\n",
    "cifar_eval = cifar_eval.batch(config.eval.batch_size, drop_remainder=True)\n",
    "svhn_eval = svhn_eval.batch(config.eval.batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data normalizer and its inverse\n",
    "scaler = datasets.get_data_scaler(config)\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 16:17:04.234719: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-12 16:17:04.234749: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-12 16:17:06.719789: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-12 16:17:06.719827: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.36GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-12 16:17:08.043499: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-12 16:17:08.043526: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "/home/cyanos/Workspace/OOD_Generative_models/score_flow-main/venv/lib/python3.10/site-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "rng, model_rng = jax.random.split(rng)\n",
    "score_model, init_model_state, initial_params = mutils.init_model(model_rng, config)\n",
    "optimizer = losses.get_optimizer(config).create(initial_params)\n",
    "state = mutils.State(step=0, optimizer=optimizer, lr=config.optim.lr,\n",
    "                    model_state=init_model_state,\n",
    "                    ema_rate=config.model.ema_rate,\n",
    "                    params_ema=initial_params,\n",
    "                    rng=rng)  # pytype: disable=wrong-keyword-args\n",
    "state = checkpoints.restore_checkpoint(checkpoint_dir, state, step=config.eval.end_ckpt)\n",
    "state = convert_checkpoint(state)\n",
    "# Setup SDEs\n",
    "sde = sde_lib.get_sde(config.training.sde, config.model)\n",
    "sampling_eps = config.sampling.smallest_time\n",
    "# Build the likelihood computation function\n",
    "likelihood_fn = likelihood.get_likelihood_fn(sde, score_model, inverse_scaler, eps=sampling_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the training state for executing on multiple devices\n",
    "pstate = flax.jax_utils.replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar_iter = iter(cifar_eval)\n",
    "# svhn_iter = iter(svhn_eval) \n",
    "# for i in range(min(len(cifar_eval), len(svhn_eval))):\n",
    "#     cifar_batch = next(cifar_iter)\n",
    "#     svhn_batch = next(svhn_iter)\n",
    "#     cifar_idx = np.random.randint(0, config.eval.batch_size)\n",
    "#     svhn_idx = np.random.randint(0, config.eval.batch_size)\n",
    "#     cifar_image = cifar_batch['image'][cifar_idx]\n",
    "#     svhn_image = svhn_batch['image'][svhn_idx]\n",
    "#     inter_images = [svhn_image + theta*(cifar_image - svhn_image) for theta in np.arange(0, 1., 0.05)]\n",
    "#     inter_images = tf.stack(inter_images, 0)\n",
    "#     inter_images = inter_images[np.newaxis, ...]\n",
    "\n",
    "#     data = jax.tree_util.tree_map(lambda x: scaler(x._numpy()), inter_images)\n",
    "#     rng, *step_rng = jax.random.split(rng, jax.local_device_count() + 1)\n",
    "#     step_rng = jnp.asarray(step_rng)\n",
    "#     bpd = likelihood_fn(step_rng, pstate, data)[0]\n",
    "#     bpd = bpd.reshape(-1)\n",
    "\n",
    "#     # Save bits/dim to disk or Google Cloud Storage\n",
    "#     bpd_npz_path = os.path.join(eval_dir,\n",
    "#                                     f\"{config.eval.bpd_dataset}_inter_bpd_{i}_{bpd[0]:.4f}_{bpd[-1]:.4f}.npz\")\n",
    "#     with tf.io.gfile.GFile(bpd_npz_path, \"wb\") as fout:\n",
    "#         io_buffer = io.BytesIO()\n",
    "#         np.savez_compressed(io_buffer, bpd)\n",
    "#         fout.write(io_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyanos/Workspace/OOD_Generative_models/score_flow-main/venv/lib/python3.10/site-packages/flax/jax_utils.py:61: FutureWarning: jax.tree_map is deprecated, and will be removed in a future release. Use jax.tree_util.tree_map instead.\n",
      "  return jax.tree_map(lambda x: x[0], tree)\n",
      "2022-08-12 16:17:23.015876: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "cifar_iter = iter(cifar_eval)\n",
    "for i in range(len(cifar_eval)):\n",
    "    cifar_batch = next(cifar_iter)\n",
    "    cifar_idx1 = np.random.randint(0, config.eval.batch_size)\n",
    "    cifar_idx2 = np.random.randint(0, config.eval.batch_size)\n",
    "    cifar_image1 = cifar_batch['image'][cifar_idx1]\n",
    "    cifar_image2 = cifar_batch['image'][cifar_idx2]\n",
    "    inter_images = [cifar_image2 + theta*(cifar_image1 - cifar_image2) for theta in np.arange(0, 1., 0.05)]\n",
    "    inter_images = tf.stack(inter_images, 0)\n",
    "    inter_images = inter_images[np.newaxis, ...]\n",
    "\n",
    "    data = jax.tree_util.tree_map(lambda x: scaler(x._numpy()), inter_images)\n",
    "    rng, *step_rng = jax.random.split(rng, jax.local_device_count() + 1)\n",
    "    step_rng = jnp.asarray(step_rng)\n",
    "    bpd = likelihood_fn(step_rng, pstate, data)[0]\n",
    "    bpd = bpd.reshape(-1)\n",
    "\n",
    "    # Save bits/dim to disk or Google Cloud Storage\n",
    "    bpd_npz_path = os.path.join(eval_dir,\n",
    "                                    f\"{config.eval.bpd_dataset}_inter_bpd_{i}_{bpd[0]:.4f}_{bpd[-1]:.4f}.npz\")\n",
    "    with tf.io.gfile.GFile(bpd_npz_path, \"wb\") as fout:\n",
    "        io_buffer = io.BytesIO()\n",
    "        np.savez_compressed(io_buffer, bpd)\n",
    "        fout.write(io_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ab3a88db3bbba6f6fddfe62f28955b2f80c7a49ce961a9bc58b5d9fef525b8a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
